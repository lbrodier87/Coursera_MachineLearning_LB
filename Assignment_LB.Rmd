---
title: "Coursera Machine Learning - Assignment"
author: "Laurent Brodier"
date: "26/05/2020"
output: html_document
---

# Introduction
One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. The goal of your project is to predict the manner in which they did the exercise. This is the "classe" variable in the training set.

# Data pre-processing
We load the following libraries: 
```{r, results='hide', warning=F}
library(caret)
library(rpart.plot)
library(rpart)
library(ggplot2)
```

We start by downloading the training and testing datasets: The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har. 
```{r, results=F}
path.training <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
path.testing <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

download.file(path.training, "training.csv", method="curl") 
download.file(path.testing, "testing.csv", method="curl") 

training.raw <- read.csv("training.csv", na.strings=c("NA","#DIV/0!", ""))
testing.raw <- read.csv("testing.csv", na.strings=c("NA","#DIV/0!", ""))
```

We then filter the datas: we remove columns that contain mostly NA, we remove columns that have nothing to do with the analysis, and finally, we remove columns that are near zero values. We started with 160 columns and end with 52. 
```{r}
#remove NA columns in training:
training <-training.raw[,colSums(is.na(training.raw)) == 0]

#remove columns unrelated to the analysis:
training <- training[,-c(1,2,3,4,5,6,7)] 

#look at near zero values: 
nzv <- nearZeroVar(training, saveMetrics = TRUE)
training <- training[,!nzv$nzv]
dim(training.raw); dim(training)
```

# ANALYSIS
## Data partitioning
We start by partition our data into training and testing datasets, using a value of 70% in the training set. 
```{r}
inTrain <- createDataPartition(training$classe, p=0.7, list=F)
train <- training[inTrain,]
test <- training[-inTrain,]
dim(train); dim(test)
```

## Deision Tree
We start our analysis by fitting a decision tree model:  
```{r}
modFit.dt <- rpart(classe~., data=train, method="class")
pred.dt <- predict(modFit.dt, test, type = "class")
cm.dt <- confusionMatrix(pred.dt, test$classe) #73.76%
accurary.dt <- paste0(round(cm.dt$overall[1]*100, 2), "%")
ose.dt <- paste0(round((1-cm.dt$overall[1])*100, 2), "%")
cm.dt
```
We visualise the decision tree using the rpart.plot package
```{r, warning=F}
rpart.plot(modFit.dt)
```
  
Finally we check the 10 most important variables with the varImp() function of the 'caret' package: 
```{r}
library(ggplot2)
v <- varImp(modFit.dt)
v$name <- rownames(v)
v <- v[order(v$Overall, decreasing = T),]
v <- v[10:1,]
ggplot(data=v, aes(y=1:dim(v)[1], x=Overall)) + 
  geom_bar(stat = 'identity', fill="green") +
  scale_y_continuous(breaks = 1:length(v$name), labels = v$name) + 
  xlab("importance (varImp)")+ ylab("variable") + theme_bw()
```
  
The decision tree (rpart) gives us an accuracy of **`r accurary.dt`**, and an out of sample error of `r ose.dt`.  

## Random Forest
We then use the random forest algorithm: 
```{r, cache=TRUE}
modFit.rf <- train(classe~., data=train, method="rf")
pred.rf <- predict(modFit.rf, test)
cm.rf <- confusionMatrix(pred.rf, test$classe) 
accurary.rf <- paste0(round(cm.rf$overall[1]*100, 2), "%")
ose.rf <- paste0(round((1-cm.rf$overall[1])*100, 2), "%")
cm.rf
```
We get an accuracy of `r accurary.rf` and an out of sample error of `r ose.rf`. 
  
We also plot the important variables: 
```{r}
library(ggplot2)
v <- varImp(modFit.rf)$importance
v$name <- rownames(v)
v <- v[order(v$Overall, decreasing = T),]
v <- v[10:1,]
ggplot(data=v, aes(y=1:dim(v)[1], x=Overall)) + 
  geom_bar(stat = 'identity', fill="green") +
  scale_y_continuous(breaks = 1:length(v$name), labels = v$name) + 
  xlab("importance (varImp)")+ ylab("variable") + theme_bw()
```

# Conclusion: 
The random forest model is better with an accuracy of `r accurary.rf` compared to the decision tree with an accuracy of `r accurary.dt`. We keep the random forest model. 

# Course Project Prediction Quiz
We apply the same pre-processing to he testing dataset than for the training dataset. 
```{r}
#remove NA columns in training:
testing <-testing.raw[,colSums(is.na(testing.raw)) == 0]

#remove columns unrelated to the analysis:
testing <- testing[,-c(1,2,3,4,5,6,7)] 

#look at near zero values: 
nzv <- nearZeroVar(testing, saveMetrics = TRUE)
testing <- testing[,!nzv$nzv]
dim(testing.raw); dim(testing)
```

We apply the prediction to the testing dataset: 
```{r}
pred <- predict(modFit.rf, testing)
pred
```